{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 451400,
          "sourceType": "datasetVersion",
          "datasetId": 205791
        }
      ],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "notebook863cfe4987",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ris-code/BasicML/blob/main/Yolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'dcsass-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F205791%2F451400%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240503%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240503T110640Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D669002c274de0c080567f24f9734867621c56cd8f517befa96049db19043032d31da6eae8f8ec9617197cefb96a095b11ac2e050b2204f16818cd26f776fb4becf4e9371fbb6ece59c4d36ff726f266d2b2d7ccb7bbb3989d6c5692b457d678222174efd8bfd817848927e777367ea0ebae743217153a1a6e71a6cba5e7952307c4751d38bf3eabd1004323f74c45087b865b149cc05548a013bb9eac85ac7871879f0fa84d87053a55f5c70110d15f1905107be366fb66f8e8ee211b99152692f190fe576567bcd107a80960f52783d7d95bf9c5a4051122f30d2e3c7d756922ed3bd389217a34a1d4de8eaab86e144037f9e24d60af83329360c106a4d810b'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "F4Xtj2yI_kMz"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from model import Darknet\n",
        "from utils.utils import non_max_suppression, load_classes\n",
        "\n",
        "# Load YOLOv3 model\n",
        "model = Darknet(\"config/yolov3.cfg\")\n",
        "model.load_weights(\"weights/yolov3.weights\")\n",
        "model.eval()\n",
        "\n",
        "# Load classes\n",
        "classes = load_classes(\"data/coco.names\")\n",
        "\n",
        "# Transformation for input images\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Function to detect objects in a frame\n",
        "def detect_objects(frame):\n",
        "    img = transform(frame).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        detections = model(img)\n",
        "        detections = non_max_suppression(detections, conf_thres=0.5, nms_thres=0.4)\n",
        "    return detections[0]\n",
        "\n",
        "# Process video\n",
        "video_path = \"/kaggle/input/dcsass-dataset/RoadAccidents/RoadAccidents001_x264.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    detections = detect_objects(frame)\n",
        "\n",
        "    if detections is not None:\n",
        "        for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections:\n",
        "            label = classes[int(cls_pred)]\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, label, (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "    cv2.imshow('Video', frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-05-03T10:29:49.702288Z",
          "iopub.execute_input": "2024-05-03T10:29:49.703617Z",
          "iopub.status.idle": "2024-05-03T10:29:57.781597Z",
          "shell.execute_reply.started": "2024-05-03T10:29:49.703567Z",
          "shell.execute_reply": "2024-05-03T10:29:57.780046Z"
        },
        "trusted": true,
        "id": "3BRsDDas_kM4",
        "outputId": "529f6d1e-84ee-4e04-8ce8-50e4a05ddf57"
      },
      "execution_count": null,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Darknet\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m non_max_suppression, load_classes\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load YOLOv3 model\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model'"
          ],
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'model'",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-03T10:47:35.080185Z",
          "iopub.execute_input": "2024-05-03T10:47:35.08082Z",
          "iopub.status.idle": "2024-05-03T10:47:57.621402Z",
          "shell.execute_reply.started": "2024-05-03T10:47:35.080775Z",
          "shell.execute_reply": "2024-05-03T10:47:57.619841Z"
        },
        "trusted": true,
        "id": "yAI66160_kM6",
        "outputId": "d411e330-2a5a-4100-893b-bcbb8bea24fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Requirement already satisfied: gitpython>=3.1.30 in /opt/conda/lib/python3.10/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 5)) (3.1.41)\nRequirement already satisfied: matplotlib>=3.3 in /opt/conda/lib/python3.10/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (3.7.5)\nRequirement already satisfied: numpy>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 7)) (1.26.4)\nRequirement already satisfied: opencv-python>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 8)) (4.9.0.80)\nCollecting pillow>=10.3.0 (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 9))\n  Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 10)) (5.9.3)\nRequirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 11)) (6.0.1)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (2.31.0)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 13)) (1.11.4)\nCollecting thop>=0.1.1 (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 14))\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (2.1.2+cpu)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 16)) (0.16.2+cpu)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 17)) (4.66.1)\nCollecting ultralytics>=8.0.232 (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18))\n  Downloading ultralytics-8.2.7-py3-none-any.whl.metadata (40 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 27)) (2.2.2)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 28)) (0.12.2)\nRequirement already satisfied: setuptools>=65.5.1 in /opt/conda/lib/python3.10/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 42)) (69.0.3)\nRequirement already satisfied: wheel>=0.38.0 in /opt/conda/lib/python3.10/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 50)) (0.42.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython>=3.1.30->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 5)) (4.0.11)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (2.9.0.post0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (2024.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (2024.2.0)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics>=8.0.232->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18)) (9.0.0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 27)) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 27)) (2023.4)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 5)) (5.0.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (1.3.0)\nDownloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nDownloading ultralytics-8.2.7-py3-none-any.whl (755 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m755.1/755.1 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pillow, thop, ultralytics\n  Attempting uninstall: pillow\n    Found existing installation: Pillow 9.5.0\n    Uninstalling Pillow-9.5.0:\n      Successfully uninstalled Pillow-9.5.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pillow-10.3.0 thop-0.1.1.post2209072238 ultralytics-8.2.7\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# Load YOLOv5 model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
        "\n",
        "# Load video\n",
        "video_path = '/kaggle/input/dcsass-dataset/RoadAccidents/RoadAccidents001_x264.mp4'\n",
        "video_capture = cv2.VideoCapture(video_path)\n",
        "print(1)\n",
        "\n",
        "while video_capture.isOpened():\n",
        "    print(1)\n",
        "    ret, frame = video_capture.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert frame to PIL image\n",
        "    pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    # Perform object detection\n",
        "    results = model(pil_image)\n",
        "\n",
        "    # Draw bounding boxes and labels on the frame\n",
        "    annotated_image = results.render()[0]\n",
        "\n",
        "    # Convert back to OpenCV format\n",
        "    annotated_frame = cv2.cvtColor(np.array(annotated_image), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Display annotated frame\n",
        "    cv2.imshow('YOLOv5 Object Detection', annotated_frame)\n",
        "\n",
        "    # Press q to exit\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release video capture and close windows\n",
        "video_capture.release()\n",
        "# cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-03T10:51:03.787524Z",
          "iopub.execute_input": "2024-05-03T10:51:03.788037Z",
          "iopub.status.idle": "2024-05-03T10:51:04.446741Z",
          "shell.execute_reply.started": "2024-05-03T10:51:03.788002Z",
          "shell.execute_reply": "2024-05-03T10:51:04.445367Z"
        },
        "trusted": true,
        "id": "L-J7oEPN_kM7",
        "outputId": "a07603f1-9cdb-4f54-effd-01cb50009345"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\nYOLOv5 ðŸš€ 2024-5-3 Python-3.10.13 torch-2.1.2+cpu CPU\n\nFusing layers... \nYOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\nAdding AutoShape... \n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "1\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# Load YOLOv5 model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
        "\n",
        "# Load video\n",
        "video_path = 'your_video.mp4'\n",
        "video_capture = cv2.VideoCapture(video_path)\n",
        "\n",
        "while video_capture.isOpened():\n",
        "    ret, frame = video_capture.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert frame to PIL image\n",
        "    pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    # Perform object detection\n",
        "    results = model(pil_image)\n",
        "\n",
        "    # Draw bounding boxes and labels on the frame\n",
        "    annotated_image = results.render()[0]\n",
        "\n",
        "    # Convert back to OpenCV format\n",
        "    annotated_frame = cv2.cvtColor(np.array(annotated_image), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Display annotated frame\n",
        "    cv2.imshow('YOLOv5 Object Detection', annotated_frame)\n",
        "\n",
        "    # Press q to exit\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release video capture\n",
        "video_capture.release()\n"
      ],
      "metadata": {
        "id": "b7aEeQuc_kM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load YOLOv5 model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
        "\n",
        "# Load video\n",
        "video_path = '/kaggle/input/dcsass-dataset/DCSASS Dataset/RoadAccidents/RoadAccidents001_x264.mp4/RoadAccidents001_x264_10.mp4'\n",
        "video_capture = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Check if video capture object is opened successfully\n",
        "if not video_capture.isOpened():\n",
        "    print(\"Error: Unable to open video file.\")\n",
        "    exit()\n",
        "\n",
        "# Get video properties\n",
        "fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
        "width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "output_video_path = 'annotated_video.mp4'\n",
        "\n",
        "# Define video writer\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "output_video = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "# Read the first frame\n",
        "ret, frame = video_capture.read()\n",
        "\n",
        "# Check if frame is read successfully\n",
        "if not ret:\n",
        "    print(\"Error: Unable to read frame from video.\")\n",
        "    exit()\n",
        "\n",
        "# Convert frame to PIL image\n",
        "pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "# Perform object detection\n",
        "results = model(pil_image)\n",
        "\n",
        "# Draw bounding boxes and labels on the frame\n",
        "annotated_image = results.render()[0]\n",
        "\n",
        "# Convert annotated frame back to OpenCV format\n",
        "annotated_frame = cv2.cvtColor(np.array(annotated_image), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "# Write annotated frame to output video\n",
        "output_video.write(annotated_frame)\n",
        "\n",
        "# Release video capture and writer\n",
        "video_capture.release()\n",
        "output_video.release()\n",
        "\n",
        "# Print message\n",
        "print(f\"Annotated video saved at: {output_video_path}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-03T11:02:59.818473Z",
          "iopub.execute_input": "2024-05-03T11:02:59.818911Z",
          "iopub.status.idle": "2024-05-03T11:03:00.482512Z",
          "shell.execute_reply.started": "2024-05-03T11:02:59.818876Z",
          "shell.execute_reply": "2024-05-03T11:03:00.481058Z"
        },
        "trusted": true,
        "id": "jNDjctGI_kM8",
        "outputId": "2ac77899-63ab-420e-e493-c580dc41efb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\nYOLOv5 ðŸš€ 2024-5-3 Python-3.10.13 torch-2.1.2+cpu CPU\n\nFusing layers... \nYOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\nAdding AutoShape... \n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Annotated video saved at: annotated_video.mp4\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def play_video(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        cv2.imshow('Video', frame)\n",
        "\n",
        "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "#     cv2.destroyAllWindows()\n",
        "\n",
        "video_path = '/kaggle/working/annotated_video.mp4'  # Replace 'path_to_your_video.mp4' with the path to your video file\n",
        "play_video(video_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-03T11:05:07.465979Z",
          "iopub.execute_input": "2024-05-03T11:05:07.466421Z",
          "iopub.status.idle": "2024-05-03T11:05:07.54048Z",
          "shell.execute_reply.started": "2024-05-03T11:05:07.466384Z",
          "shell.execute_reply": "2024-05-03T11:05:07.538888Z"
        },
        "trusted": true,
        "id": "v_2qgNaI_kM8",
        "outputId": "33eb84de-9e95-48e5-95bd-fbebbe31fe03"
      },
      "execution_count": null,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#     cv2.destroyAllWindows()\u001b[39;00m\n\u001b[1;32m     20\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/annotated_video.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace 'path_to_your_video.mp4' with the path to your video file\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[43mplay_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[4], line 12\u001b[0m, in \u001b[0;36mplay_video\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVideo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m25\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /io/opencv/modules/highgui/src/window.cpp:1272: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
          ],
          "ename": "error",
          "evalue": "OpenCV(4.9.0) /io/opencv/modules/highgui/src/window.cpp:1272: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
          "output_type": "error"
        }
      ]
    }
  ]
}